{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee6d49c",
   "metadata": {},
   "source": [
    "<!-- ## Rag -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b11776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key= GROQ_API_KEY,temperature=0.7\n",
    ")\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "\tapi_key=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e524e",
   "metadata": {},
   "source": [
    "## Chroma check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda6e528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrewAI storage location: /home/ahmed/snap/code/219/.local/share/Agent\n",
      "üìÅ chroma.sqlite3\n",
      "üìÅ chromadb-b6e1f73bd8c9480e42e90856fc17defb.lock\n",
      "üìÅ .crewai_user.json\n",
      "üìÅ ee9e4d22-5caf-4327-a98e-5574ad9bf99c\n",
      "üìÅ latest_kickoff_task_outputs.db\n"
     ]
    }
   ],
   "source": [
    "from crewai.utilities.paths import db_storage_path\n",
    "import os\n",
    "\n",
    "storage_path = db_storage_path()\n",
    "print(f\"CrewAI storage location: {storage_path}\")\n",
    "\n",
    "# ‡¶∏‡¶¨ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®\n",
    "if os.path.exists(storage_path):\n",
    "    for item in os.listdir(storage_path):\n",
    "        print(f\"üìÅ {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988c92a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage path: /home/ahmed/snap/code/219/.local/share/Agent\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from crewai.utilities.paths import db_storage_path\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# CrewAI storage path ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßÅ‡¶®\n",
    "storage_path = db_storage_path()\n",
    "print(f\"Storage path: {storage_path}\")\n",
    "\n",
    "# # ‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ storage ‡¶°‡¶ø‡¶≤‡¶ø‡¶ü ‡¶ï‡¶∞‡ßÅ‡¶®\n",
    "# if os.path.exists(storage_path):\n",
    "#     shutil.rmtree(storage_path)\n",
    "#     print(\"‚úÖ Storage deleted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrewAI storage location: /home/ahmed/snap/code/219/.local/share/Agent\n",
      "üìÅ chroma.sqlite3\n",
      "üìÅ chromadb-b6e1f73bd8c9480e42e90856fc17defb.lock\n",
      "üìÅ .crewai_user.json\n",
      "üìÅ ee9e4d22-5caf-4327-a98e-5574ad9bf99c\n",
      "üìÅ latest_kickoff_task_outputs.db\n"
     ]
    }
   ],
   "source": [
    "from crewai.utilities.paths import db_storage_path\n",
    "import os\n",
    "\n",
    "storage_path = db_storage_path()\n",
    "print(f\"CrewAI storage location: {storage_path}\")\n",
    "\n",
    "# ‡¶∏‡¶¨ ‡¶´‡ßã‡¶≤‡ßç‡¶°‡¶æ‡¶∞ ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®\n",
    "if os.path.exists(storage_path):\n",
    "    for item in os.listdir(storage_path):\n",
    "        print(f\"üìÅ {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d94566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47296816",
   "metadata": {},
   "source": [
    "## Slow query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Crew, Task, LLM\n",
    "from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource\n",
    "\n",
    "\n",
    "# ‡ß©. PDF Knowledge Source ‡¶§‡ßà‡¶∞‡¶ø\n",
    "pdf_source = PDFKnowledgeSource(\n",
    "    file_paths=[\"MachineLearning.pdf\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "# ‡ß™. Agent ‡¶§‡ßà‡¶∞‡¶ø\n",
    "agent = Agent(\n",
    "    role=\"PDF Knowledge Expert\",\n",
    "    goal=\"Answer questions based on the provided PDF documents.\",\n",
    "    backstory=\"An AI assistant that extracts and provides information from PDFs.\",\n",
    "    llm=llm,\n",
    "    knowledge_sources=[pdf_source],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ‡ß´. Task ‡¶§‡ßà‡¶∞‡¶ø\n",
    "task = Task(\n",
    "    description=\"Answer this question: {input}\",\n",
    "    expected_output=\"A clear and concise answer from the PDF.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "# ‡ß¨. Crew ‡¶§‡ßà‡¶∞‡¶ø\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    "    embedder={\n",
    "        \"provider\": \"sentence-transformer\",\n",
    "        \"config\": {\"model_name\": \"all-MiniLM-L6-v2\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "# # ‡ß≠. ‡¶∞‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®\n",
    "# if __name__ == \"__main__\":\n",
    "#     result = crew.kickoff(inputs={\"input\": \"Should You Buy This Book?\"})\n",
    "#     print(\"\\n=== Result ===\")\n",
    "#     print(result)\n",
    "    \n",
    "#     # ‡¶∏‡ßç‡¶ü‡ßã‡¶∞‡ßá‡¶ú ‡¶™‡¶æ‡¶• ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßÅ‡¶®\n",
    "#     from crewai.utilities.paths import db_storage_path\n",
    "#     print(f\"\\nStorage path: {db_storage_path()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5509a2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c74bb128",
   "metadata": {},
   "source": [
    "## üí° ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡ßá‡¶™‡ßá:\n",
    "\n",
    "| ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º     | PDFSearchTool                            | PDFKnowledgeSource                           |\n",
    "| --------- | ---------------------------------------- | -------------------------------------------- |\n",
    "| ‡¶ß‡¶∞‡¶®       | Tool (‡¶ü‡ßÅ‡¶≤)                               | Knowledge Source (‡¶ú‡ßç‡¶û‡¶æ‡¶® ‡¶â‡ßé‡¶∏)                 |\n",
    "| ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ß‡¶∞‡¶® | Agent ‡¶®‡¶ø‡¶ú‡ßá ‡¶∏‡¶ø‡¶¶‡ßç‡¶ß‡¶æ‡¶®‡ßç‡¶§ ‡¶®‡ßá‡¶Ø‡¶º ‡¶ï‡¶ñ‡¶® ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö ‡¶ï‡¶∞‡¶¨‡ßá | ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø task ‡¶è context ‡¶¶‡ßá‡¶Ø‡¶º |\n",
    "| ‡¶ó‡¶§‡¶ø       | ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§ (‡¶∂‡ßÅ‡¶ß‡ßÅ query ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡¶Ø‡¶º‡ßÄ ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö)        | ‡¶ß‡ßÄ‡¶∞ (‡¶∏‡¶Æ‡ßç‡¶™‡ßÇ‡¶∞‡ßç‡¶£ PDF ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡ßá)                |\n",
    "| ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞   | `tools=[pdf_tool]`                       | `knowledge_sources=[pdf_source]`             |\n",
    "\n",
    "\n",
    "- PDFSearchTool: ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§, question-specific, agent ‡¶®‡¶ø‡¶ú‡ßá decide ‡¶ï‡¶∞‡ßá ‡¶ï‡¶ñ‡¶® ‡¶∏‡¶æ‡¶∞‡ßç‡¶ö‡•§\n",
    "\n",
    "- PDFKnowledgeSource: ‡¶ß‡ßÄ‡¶∞, ‡¶™‡ßÅ‡¶∞‡ßã PDF process ‡¶ï‡¶∞‡ßá, ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø task automatically context ‡¶™‡¶æ‡¶Ø‡¶º‡•§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25452fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2dd69c2",
   "metadata": {},
   "source": [
    "## Faster query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c84ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/miniconda3/envs/aiapp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Task, LLM\n",
    "from crewai_tools import PDFSearchTool\n",
    "\n",
    "\n",
    "# PDFSearchTool ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶® - ‡¶è‡¶ü‡¶ø ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§\n",
    "pdf_tool = PDFSearchTool(\n",
    "    pdf='knowledge/MachineLearning.pdf',\n",
    "    config={\n",
    "        \"embedding_model\": {\n",
    "            \"provider\": \"sentence-transformer\",\n",
    "            \"config\": {\"model\": \"all-MiniLM-L6-v2\"}\n",
    "        },\n",
    "        \"vectordb\": {\n",
    "            \"provider\": \"chromadb\",\n",
    "            \"config\": {}\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ecfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"llama-3.1-8b-instant\", # The provider prefix is 'groq/'\n",
    "#     # Replace with your actual key\n",
    "#     api_key= GROQ_API_KEY,temperature=0.7\n",
    "# )\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"huggingface/meta-llama/Llama-3.1-8B-Instruct\",\n",
    "\tapi_key=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ")\n",
    "\n",
    "# from crewai import LLM\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=\"gemini/gemini-2.0-flash\",\n",
    "#     # api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "#     api_key=\"\"\n",
    "# )\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"PDF Knowledge Expert\",\n",
    "    goal=\"Answer questions based on PDF documents.\",\n",
    "    backstory=\"An AI assistant that extracts information from PDFs.\",\n",
    "    llm=llm,\n",
    "    tools=[pdf_tool],  # tools ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶¶‡¶ø‡¶®, knowledge_sources ‡¶®‡¶Ø‡¶º\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Answer: {input}\",\n",
    "    expected_output=\"Short and clear answer from the PDF.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"input\": \"Decision Tree Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71d5ca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer: Semi-Supervised Learning?', name='Answer: Semi-Supervised Learning?', expected_output='Short and clear answer from the PDF.', summary='Answer: Semi-Supervised Learning?...', raw='1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.', pydantic=None, json_dict=None, agent='PDF Knowledge Expert', output_format=<OutputFormat.RAW: 'raw'>, messages=[{'role': 'system', 'content': 'You are PDF Knowledge Expert. An AI assistant that extracts information from PDFs.\\nYour personal goal is: Answer questions based on PDF documents.\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Search a PDF\\'s content\\nTool Arguments: {\\n  \"description\": \"Input for PDFSearchTool.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"Mandatory query you want to use to search the PDF\\'s content\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  },\\n  \"required\": [\\n    \"query\"\\n  ],\\n  \"title\": \"FixedPDFSearchToolSchema\",\\n  \"type\": \"object\",\\n  \"additionalProperties\": false\\n}\\nTool Description: A tool that can be used to semantic search a query the knowledge/MachineLearning.pdf PDF\\'s content.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Search a PDF\\'s content], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```'}, {'role': 'user', 'content': '\\nCurrent Task: Answer: Decision Tree Learning?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:'}, {'role': 'assistant', 'content': 'Action: Search a PDF\\'s content\\nAction Input: {\"query\": \"Decision Tree Learning\"}\\nObservation: Relevant Content:\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n9\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n9\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n9\\n\\n\\n\\n\\n\\n\\nPage 36:\\n\\nS={(x1,\\xa0y1),\\xa0(x2,\\xa0y2),\\xa0(x3,\\xa0y3),\\n\\n(x4,\\xa0y4),\\xa0(x5,\\xa0y5),\\xa0(x6,\\xa0y6),\\n\\n(x7,\\xa0y7),\\xa0(x8,\\xa0y8),\\xa0(x9,\\xa0y9),\\n\\n(x10,\\xa0y10),\\xa0(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\n\\nx\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y3+y4+y5\\xa0\\n\\n+y6+y7+y8+y9+y10+y11+y12)/12\\n\\nPr(y\\xa0=\\xa01|x)\\n\\n(a)\\n\\nx\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y4\\xa0\\n\\n+y6+y7+y8+y9)/7\\n\\nPr(y\\xa0=\\xa01|x)\\n\\nx(3)\\xa0<\\xa018.3?\\n\\nS\\xad\\xa0=\\xa0{(x1,\\xa0y1),\\xa0(x2,\\xa0y2),\\n\\n(x4,\\xa0y4),\\xa0(x6,\\xa0y6),\\xa0(x7,\\xa0y7),\\n\\n(x8,\\xa0y8),\\xa0(x9,\\xa0y9)}\\xa0\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\n\\n(y3+y5+y10+y11+y12)/5\\n\\nPr(y\\xa0=\\xa01|x)\\n\\nS+\\xa0=\\xa0{(x3,\\xa0y3),\\xa0(x5,\\xa0y5),\\xa0(x10,\\xa0y10),\\n\\n(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\xa0\\n\\nYes\\n\\nNo\\n\\n(b)\\n\\nFigure 4: An illustration of a decision tree building algorithm. The set S contains 12 labeled\\n\\nexamples. (a) In the beginning, the decision tree only contains the start node; it makes the\\n\\nsame prediction for any input. (b) The decision tree after the Ô¨Årst split; it tests whether\\n\\nfeature 3 is less than 18.3 and, depending on the result, the prediction is made in one of the\\n\\ntwo leaf nodes.\\n\\nThe ID3 learning algorithm works as follows. Let S denote a set of labeled examples. In the\\n\\nbeginning, the decision tree only has a start node that contains all examples: S\\n\\ndef\\n\\n= {(xi, yi)}N\\n\\ni=1.\\n\\nStart with a constant model f S\\n\\nID3:\\n\\nf S\\n\\nID3 = 1\\n\\n|S|\\n\\n√ø\\n\\n(x,y)≈ìS\\n\\ny.\\n\\n(6)\\n\\nThe prediction given by the above model, f S\\n\\nID3(x), would be the same for any input x. The\\n\\ncorresponding decision tree is shown in Ô¨Åg 4a.\\n\\nThen we search through all features j = 1, . . . , D and all thresholds t, and split the set S\\n\\ninto two subsets: S‚â†\\n\\ndef\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n9\\n\\n\\n\\n\\n\\nPage 35:\\n\\nBecause ln is a strictly increasing function, maximizing this function is the same as maximizing\\n\\nits argument, and the solution to this new optimization problem is the same as the solution\\n\\nto the original problem.\\n\\nContrary to linear regression, there‚Äôs no closed form solution to the above optimization\\n\\nproblem. A typical numerical optimization procedure used in such cases is gradient descent.\\n\\nI talk about it in the next chapter.\\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n9\\n\\n\\n\\n\\n\\n\\nPage 36:\\n\\nS={(x1,\\xa0y1),\\xa0(x2,\\xa0y2),\\xa0(x3,\\xa0y3),\\n\\n(x4,\\xa0y4),\\xa0(x5,\\xa0y5),\\xa0(x6,\\xa0y6),\\n\\n(x7,\\xa0y7),\\xa0(x8,\\xa0y8),\\xa0(x9,\\xa0y9),\\n\\n(x10,\\xa0y10),\\xa0(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\n\\nx\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y3+y4+y5\\xa0\\n\\n+y6+y7+y8+y9+y10+y11+y12)/12\\n\\nPr(y\\xa0=\\xa01|x)\\n\\n(a)\\n\\nx\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\xa0(y1+y2+y4\\xa0\\n\\n+y6+y7+y8+y9)/7\\n\\nPr(y\\xa0=\\xa01|x)\\n\\nx(3)\\xa0<\\xa018.3?\\n\\nS\\xad\\xa0=\\xa0{(x1,\\xa0y1),\\xa0(x2,\\xa0y2),\\n\\n(x4,\\xa0y4),\\xa0(x6,\\xa0y6),\\xa0(x7,\\xa0y7),\\n\\n(x8,\\xa0y8),\\xa0(x9,\\xa0y9)}\\xa0\\n\\nPr(y\\xa0=\\xa01|x)\\xa0=\\n\\n(y3+y5+y10+y11+y12)/5\\n\\nPr(y\\xa0=\\xa01|x)\\n\\nS+\\xa0=\\xa0{(x3,\\xa0y3),\\xa0(x5,\\xa0y5),\\xa0(x10,\\xa0y10),\\n\\n(x11,\\xa0y11),\\xa0(x12,\\xa0y12)}\\xa0\\n\\nYes\\n\\nNo\\n\\n(b)\\n\\nFigure 4: An illustration of a decision tree building algorithm. The set S contains 12 labeled\\n\\nexamples. (a) In the beginning, the decision tree only contains the start node; it makes the\\n\\nsame prediction for any input. (b) The decision tree after the Ô¨Årst split; it tests whether\\n\\nfeature 3 is less than 18.3 and, depending on the result, the prediction is made in one of the\\n\\ntwo leaf nodes.\\n\\nThe ID3 learning algorithm works as follows. Let S denote a set of labeled examples. In the\\n\\nbeginning, the decision tree only has a start node that contains all examples: S\\n\\ndef\\n\\n= {(xi, yi)}N\\n\\ni=1.\\n\\nStart with a constant model f S\\n\\nID3:\\n\\nf S\\n\\nID3 = 1\\n\\n|S|\\n\\n√ø\\n\\n(x,y)≈ìS\\n\\ny.\\n\\n(6)\\n\\nThe prediction given by the above model, f S\\n\\nID3(x), would be the same for any input x. The\\n\\ncorresponding decision tree is shown in Ô¨Åg 4a.\\n\\nThen we search through all features j = 1, . . . , D and all thresholds t, and split the set S\\n\\ninto two subsets: S‚â†\\n\\ndef'}, {'role': 'assistant', 'content': 'Thought: I now know the final answer\\nFinal Answer: \\n\\n3.3\\n\\nDecision Tree Learning\\n\\nA decision tree is an acyclic graph that can be used to make decisions. In each branching\\n\\nnode of the graph, a speciÔ¨Åc feature j of the feature vector is examined. If the value of the\\n\\nfeature is below a speciÔ¨Åc threshold, then the left branch is followed; otherwise, the right\\n\\nbranch is followed. As the leaf node is reached, the decision is made about the class to which\\n\\nthe example belongs.\\n\\nAs the title of the section suggests, a decision tree can be learned from data.\\n\\n3.3.1\\n\\nProblem Statement\\n\\nLike previously, we have a collection of labeled examples; labels belong to the set {0, 1}. We\\n\\nwant to build a decision tree that would allow us to predict the class of an example given a\\n\\nfeature vector.\\n\\n3.3.2\\n\\nSolution\\n\\nThere are various formulations of the decision tree learning algorithm. In this book, we\\n\\nconsider just one, called ID3.\\n\\nThe optimization criterion, in this case, is the average log-likelihood:\\n\\n1\\n\\nN\\n\\nN\\n\\n√ø\\n\\ni=1\\n\\nyi ln fID3(xi) + (1 ‚â†yi) ln (1 ‚â†fID3(xi)),\\n\\n(5)\\n\\nwhere fID3 is a decision tree.\\n\\nBy now, it looks very similar to logistic regression. However, contrary to the logistic regression\\n\\nlearning algorithm which builds a parametric model fw√∫,b√∫ by Ô¨Ånding an optimal solution\\n\\nto the optimization criterion, the ID3 algorithm optimizes it approximately by constructing a\\n\\nnon-parametric model fID3(x)\\n\\ndef\\n\\n= Pr(y = 1|x).'}, {'role': 'system', 'content': 'You are PDF Knowledge Expert. An AI assistant that extracts information from PDFs.\\nYour personal goal is: Answer questions based on PDF documents.\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Search a PDF\\'s content\\nTool Arguments: {\\n  \"description\": \"Input for PDFSearchTool.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"Mandatory query you want to use to search the PDF\\'s content\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  },\\n  \"required\": [\\n    \"query\"\\n  ],\\n  \"title\": \"FixedPDFSearchToolSchema\",\\n  \"type\": \"object\",\\n  \"additionalProperties\": false\\n}\\nTool Description: A tool that can be used to semantic search a query the knowledge/MachineLearning.pdf PDF\\'s content.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Search a PDF\\'s content], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```'}, {'role': 'user', 'content': '\\nCurrent Task: Answer: Classification vs. Regression?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:'}, {'role': 'assistant', 'content': 'Action: Search a PDF\\'s content\\nAction Input: {\"query\": \"Classification vs. Regression\"}\\nObservation: Relevant Content:\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13\\n\\n\\n\\n\\n\\nPage 27:\\nThe\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13\\n\\n\\n\\n\\n\\nPage 27:\\nThe\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13\\n\\n\\n\\n\\n\\nPage 26:\\n\\nThe regression problem is solved by a regression learning algorithm that takes a collection\\n\\nof labeled examples as inputs and produces a model that can take an unlabeled example as\\n\\ninput and output a target.\\n\\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13\\n\\n\\n\\n\\n\\nPage 27:\\nThe\\nHundred-\\nPage\\nMachine\\nLearning\\nBook\\nAndriy Burkov'}, {'role': 'assistant', 'content': 'Thought: I now know the final answer\\nFinal Answer: \\n2.7\\n\\nModel-Based vs. Instance-Based Learning\\n\\nMost supervised learning algorithms are model-based.\\n\\nWe have already seen one such\\n\\nalgorithm: SVM. Model-based learning algorithms use the training data to create a model\\n\\nthat has parameters learned from the training data. In SVM, the two parameters we saw\\n\\nwere w√∫ and b√∫. After the model was built, the training data can be discarded.\\n\\nInstance-based learning algorithms use the whole dataset as the model. One instance-based\\n\\nalgorithm frequently used in practice is k-Nearest Neighbors (kNN). In classiÔ¨Åcation, to\\n\\npredict a label for an input example the kNN algorithm looks at the close neighborhood of\\n\\nthe input example in the space of feature vectors and outputs the label that it saw the most\\n\\noften in this close neighborhood.\\n\\n2.8\\n\\nShallow vs. Deep Learning\\n\\nA shallow learning algorithm learns the parameters of the model directly from the features\\n\\nof the training examples. Most supervised learning algorithms are shallow. The notorious\\n\\nexceptions are neural network learning algorithms, speciÔ¨Åcally those that build neural\\n\\nnetworks with more than one layer between input and output. Such neural networks are\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\n\\ncalled deep neural networks. In deep neural network learning (or, simply, deep learning),\\n\\ncontrary to shallow learning, most model parameters are learned not directly from the features\\n\\nof the training examples, but from the outputs of the preceding layers.\\n\\nDon‚Äôt worry if you don‚Äôt understand what that means right now. We look at neural networks\\n\\nmore closely in Chapter 6.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n13'}, {'role': 'system', 'content': 'You are PDF Knowledge Expert. An AI assistant that extracts information from PDFs.\\nYour personal goal is: Answer questions based on PDF documents.\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Search a PDF\\'s content\\nTool Arguments: {\\n  \"description\": \"Input for PDFSearchTool.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"Mandatory query you want to use to search the PDF\\'s content\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  },\\n  \"required\": [\\n    \"query\"\\n  ],\\n  \"title\": \"FixedPDFSearchToolSchema\",\\n  \"type\": \"object\",\\n  \"additionalProperties\": false\\n}\\nTool Description: A tool that can be used to semantic search a query the knowledge/MachineLearning.pdf PDF\\'s content.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Search a PDF\\'s content], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```'}, {'role': 'user', 'content': '\\nCurrent Task: Answer: Semi-Supervised Learning?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:'}, {'role': 'assistant', 'content': 'Action: Search a PDF\\'s content\\nAction Input: {\"query\": \"Semi-Supervised Learning\"}\\nObservation: Relevant Content:\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains\\n\\n\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Search a PDF\\'s content\\nTool Arguments: {\\n  \"description\": \"Input for PDFSearchTool.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"Mandatory query you want to use to search the PDF\\'s content\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  },\\n  \"required\": [\\n    \"query\"\\n  ],\\n  \"title\": \"FixedPDFSearchToolSchema\",\\n  \"type\": \"object\",\\n  \"additionalProperties\": false\\n}\\nTool Description: A tool that can be used to semantic search a query the knowledge/MachineLearning.pdf PDF\\'s content.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Search a PDF\\'s content], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```'}, {'role': 'assistant', 'content': 'Thought: I now know the final answer\\nFinal Answer: \\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.'}])], token_usage=UsageMetrics(total_tokens=45124, prompt_tokens=44208, cached_prompt_tokens=0, completion_tokens=916, successful_requests=6))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"input\": \"Semi-Supervised Learning?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02cf25e2",
   "metadata": {},
   "source": [
    "### agent2 wikepedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c6dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import tool\n",
    "from crewai_tools import SerperDevTool\n",
    "import wikipedia\n",
    "\n",
    "serper_search = SerperDevTool()\n",
    "\n",
    "@tool(\"Wikipedia Search\")\n",
    "def wikipedia_search(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for information.\"\"\"\n",
    "    try:\n",
    "        return wikipedia.summary(query, sentences=5)\n",
    "    except:\n",
    "        return \"No results found.\"\n",
    "\n",
    "\n",
    "from crewai import LLM\n",
    "\n",
    "# llm = LLM(\n",
    "#     model=\"gemini/gemini-2.5-flash-lite\", # gemma-3-12b\n",
    "#     api_key=\"\"\n",
    "# )\n",
    "\n",
    "# from crewai import LLM\n",
    "\n",
    "# llm = LLM(\n",
    "#     provider=\"groq\",\n",
    "#     model=\"llama-3.1-8b-instant\",\n",
    "#     api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"input\": \"whats is agentic ai?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = crew.kickoff(inputs={\"input\": \"whats is Linear Regression?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23b936",
   "metadata": {},
   "source": [
    "## single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2bccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model = \"huggingface/meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    # model=\"huggingface/meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    api_key= os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94846fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/miniconda3/envs/aiapp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Task, LLM\n",
    "from crewai_tools import PDFSearchTool\n",
    "\n",
    "\n",
    "# PDFSearchTool ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶® - ‡¶è‡¶ü‡¶ø ‡¶¶‡ßç‡¶∞‡ßÅ‡¶§\n",
    "pdf_tool = PDFSearchTool(\n",
    "    pdf='knowledge/MachineLearning.pdf',\n",
    "    config={\n",
    "        \"embedding_model\": {\n",
    "            \"provider\": \"sentence-transformer\",\n",
    "            \"config\": {\"model\": \"all-MiniLM-L6-v2\"}\n",
    "        },\n",
    "        \"vectordb\": {\n",
    "            \"provider\": \"chromadb\",\n",
    "            \"config\": {}\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb71c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_system_template = \"\"\"You are {role}. {backstory}\n",
    "\n",
    "Your goal is: {goal}\n",
    "\n",
    "Rules:\n",
    "- Always search and use the PDF content first.\n",
    "- If the PDF does not contain relevant information,search Wikipedia.\n",
    "- Do not add external knowledge beyond PDF or Wikipedia.\n",
    "- Keep answers short, clear, and factual.\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt_template = \"\"\"Question: {input}\n",
    "\n",
    "Instructions:\n",
    "- First, try to answer using the PDF content.\n",
    "- If the PDF does not contain relevant context,then go wikipedia_search tool.\n",
    "- Do not include assumptions or extra explanations.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"Research Assistant\",\n",
    "    goal=\"Answer user questions using PDF first, then Wikipedia as fallback\",\n",
    "    backstory=\"Prioritize PDF content, use Wikipedia strictly as fallback.\",\n",
    "    system_template=custom_system_template,\n",
    "    prompt_template=custom_prompt_template,\n",
    "    use_system_prompt=True,\n",
    "    llm=llm,\n",
    "    tools=[pdf_tool, wikipedia_search],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "task = Task(\n",
    "    description=\"Answer this user input: {input} using PDF first, if not found use Wikipedia\",\n",
    "    expected_output=\"Short answer from PDF or Wikipedia\",\n",
    "    agent=agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "827ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "    # Create Agent with Better Instructions\n",
    "    # =========================\n",
    "custom_system_template = \"\"\"You are {role}. {backstory}\n",
    "\n",
    "Your goal is: {goal}\n",
    "\n",
    "STRICT RULES:\n",
    "1. FIRST search the PDF for relevant content using the PDF tool\n",
    "2. ONLY if PDF search returns NO results, then use Wikipedia\n",
    "3. NEVER invent or add external knowledge\n",
    "4. Always cite your source: (PDF) or (Wikipedia)\n",
    "5. If no information found in either source, say: \"I couldn't find this information in the PDF or Wikipedia.\"\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt_template = \"\"\"QUESTION: {input}\n",
    "\n",
    "SEARCH INSTRUCTIONS:\n",
    "1. Search PDF for relevant content\n",
    "2. If PDF has content, use it\n",
    "3. If PDF has NO content, search Wikipedia\n",
    "4. If neither has content, state clearly\n",
    "\n",
    "ANSWER FORMAT:\n",
    "- Start with direct answer\n",
    "- Include key points\n",
    "- End with source: (PDF) or (Wikipedia)\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent(\n",
    "    role=\"PDF Knowledge Expert\",\n",
    "    goal=\"Answer questions accurately using PDF content first, Wikipedia only as fallback\",\n",
    "    backstory=\"Prioritize PDF content, use Wikipedia strictly as fallback.\",\n",
    "    system_template=custom_system_template,\n",
    "    prompt_template=custom_prompt_template,\n",
    "    use_system_prompt=True,\n",
    "    llm=llm,\n",
    "    tools=[pdf_tool,wikipedia_search],\n",
    "    # verbose=True,\n",
    "    max_iter=3,\n",
    "    allow_delegation=False\n",
    ")\n",
    "\n",
    "\n",
    "# agent = Agent(\n",
    "#     role=\"PDF Knowledge Expert\",\n",
    "#     goal=\"Answer questions based on PDF documents.\",\n",
    "#     backstory=\"An AI assistant that extracts information from PDFs.\",\n",
    "#     llm=llm,\n",
    "#     tools=[pdf_tool],  # tools ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶¶‡¶ø‡¶®, knowledge_sources ‡¶®‡¶Ø‡¶º\n",
    "#     # verbose=True\n",
    "# )\n",
    "\n",
    "task = Task(\n",
    "    description=\"Answer: {input}\",\n",
    "    expected_output=\"Short and clear answer from the PDF.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    # verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='To answer the question: \"Semi-Supervised Learning?\"\\n\\n**Direct Answer:**\\nSemi-supervised learning is the field of study that focuses on the development of algorithms that learn from both labeled and unlabeled data.\\n\\n**Key Points:**\\n\\n- Semi-supervised learning combines supervised and unsupervised learning techniques.\\n- It is used in scenarios where large amounts of labeled data are not available but unlabeled data is abundant.\\n- The goal of semi-supervised learning is to reduce the need for labeled data and improve the overall performance of machine learning models.\\n- Semi-supervised learning algorithms can be divided into two main categories: graph-based and manifold-based methods.\\n\\n**Source:** (Wikipedia)', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer: Semi-Supervised Learning?', name='Answer: Semi-Supervised Learning?', expected_output='Short and clear answer from the PDF.', summary='Answer: Semi-Supervised Learning?...', raw='To answer the question: \"Semi-Supervised Learning?\"\\n\\n**Direct Answer:**\\nSemi-supervised learning is the field of study that focuses on the development of algorithms that learn from both labeled and unlabeled data.\\n\\n**Key Points:**\\n\\n- Semi-supervised learning combines supervised and unsupervised learning techniques.\\n- It is used in scenarios where large amounts of labeled data are not available but unlabeled data is abundant.\\n- The goal of semi-supervised learning is to reduce the need for labeled data and improve the overall performance of machine learning models.\\n- Semi-supervised learning algorithms can be divided into two main categories: graph-based and manifold-based methods.\\n\\n**Source:** (Wikipedia)', pydantic=None, json_dict=None, agent='PDF Knowledge Expert', output_format=<OutputFormat.RAW: 'raw'>, messages=[{'role': 'user', 'content': 'You are PDF Knowledge Expert. Prioritize PDF content, use Wikipedia strictly as fallback.\\n\\nYour goal is: Answer questions accurately using PDF content first, Wikipedia only as fallback\\n\\nSTRICT RULES:\\n1. FIRST search the PDF for relevant content using the PDF tool\\n2. ONLY if PDF search returns NO results, then use Wikipedia\\n3. NEVER invent or add external knowledge\\n4. Always cite your source: (PDF) or (Wikipedia)\\n5. If no information found in either source, say: \"I couldn\\'t find this information in the PDF or Wikipedia.\"\\n\\nQUESTION: Answer: Semi-Supervised Learning?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nSEARCH INSTRUCTIONS:\\n1. Search PDF for relevant content\\n2. If PDF has content, use it\\n3. If PDF has NO content, search Wikipedia\\n4. If neither has content, state clearly\\n\\nANSWER FORMAT:\\n- Start with direct answer\\n- Include key points\\n- End with source: (PDF) or (Wikipedia)'}, {'role': 'assistant', 'content': 'To answer the question: \"Semi-Supervised Learning?\"\\n\\n**Direct Answer:**\\nSemi-supervised learning is the field of study that focuses on the development of algorithms that learn from both labeled and unlabeled data.\\n\\n**Key Points:**\\n\\n- Semi-supervised learning combines supervised and unsupervised learning techniques.\\n- It is used in scenarios where large amounts of labeled data are not available but unlabeled data is abundant.\\n- The goal of semi-supervised learning is to reduce the need for labeled data and improve the overall performance of machine learning models.\\n- Semi-supervised learning algorithms can be divided into two main categories: graph-based and manifold-based methods.\\n\\n**Source:** (Wikipedia)'}])], token_usage=UsageMetrics(total_tokens=54465, prompt_tokens=52194, cached_prompt_tokens=0, completion_tokens=2271, successful_requests=15))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    # verbose=True,\n",
    "    # stream=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"input\": \"Semi-Supervised Learning?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5604dd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='Page 8:\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer: Semi-Supervised Learning?', name='Answer: Semi-Supervised Learning?', expected_output='Short and clear answer from the PDF.', summary='Answer: Semi-Supervised Learning?...', raw='Page 8:\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.', pydantic=None, json_dict=None, agent='PDF Knowledge Expert', output_format=<OutputFormat.RAW: 'raw'>, messages=[{'role': 'system', 'content': 'You are PDF Knowledge Expert. An AI assistant that extracts information from PDFs.\\nYour personal goal is: Answer questions based on PDF documents.\\nYou ONLY have access to the following tools, and should NEVER make up tools that are not listed here:\\n\\nTool Name: Search a PDF\\'s content\\nTool Arguments: {\\n  \"description\": \"Input for PDFSearchTool.\",\\n  \"properties\": {\\n    \"query\": {\\n      \"description\": \"Mandatory query you want to use to search the PDF\\'s content\",\\n      \"title\": \"Query\",\\n      \"type\": \"string\"\\n    }\\n  },\\n  \"required\": [\\n    \"query\"\\n  ],\\n  \"title\": \"FixedPDFSearchToolSchema\",\\n  \"type\": \"object\",\\n  \"additionalProperties\": false\\n}\\nTool Description: A tool that can be used to semantic search a query the knowledge/MachineLearning.pdf PDF\\'s content.\\n\\nIMPORTANT: Use the following format in your response:\\n\\n```\\nThought: you should always think about what to do\\nAction: the action to take, only one name of [Search a PDF\\'s content], just the name, exactly as it\\'s written.\\nAction Input: the input to the action, just a simple JSON object, enclosed in curly braces, using \" to wrap keys and values.\\nObservation: the result of the action\\n```\\n\\nOnce all necessary information is gathered, return the following format:\\n\\n```\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n```'}, {'role': 'user', 'content': '\\nCurrent Task: Answer: Semi-Supervised Learning?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nBegin! This is VERY important to you, use the tools available and give your best Final Answer, your job depends on it!\\n\\nThought:'}, {'role': 'assistant', 'content': 'Thought: I need to search the PDF for the term \"Semi-Supervised Learning\"\\nAction: Search a PDF\\'s content\\nAction Input: {\"query\": \"Semi-Supervised Learning\"}\\nObservation: Relevant Content:\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains\\n\\n\\n\\n\\n\\nPage 8:\\n\\n1.2.2\\n\\nUnsupervised Learning\\n\\nIn unsupervised learning, the dataset is a collection of unlabeled examples {xi}N\\n\\ni=1.\\n\\nAgain, x is a feature vector, and the goal of an unsupervised learning algorithm is\\n\\nto create a model that takes a feature vector x as input and either transforms it into\\n\\nanother vector or into a value that can be used to solve a practical problem. For example,\\n\\nin clustering, the model returns the id of the cluster for each feature vector in the dataset.\\n\\nIn dimensionality reduction, the output of the model is a feature vector that has fewer\\n\\nfeatures than the input x; in outlier detection, the output is a real number that indicates\\n\\nhow x is diÔ¨Äerent from a ‚Äútypical‚Äù example in the dataset.\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.\\n\\n1.2.4\\n\\nReinforcement Learning\\n\\nReinforcement learning is a subÔ¨Åeld of machine learning where the machine ‚Äúlives‚Äù in an\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\n\\nenvironment and is capable of perceiving the state of that environment as a vector of\\n\\nfeatures. The machine can execute actions in every state. DiÔ¨Äerent actions bring diÔ¨Äerent\\n\\nrewards and could also move the machine to another state of the environment. The goal\\n\\nof a reinforcement learning algorithm is to learn a policy. A policy is a function f (similar\\n\\nto the model in supervised learning) that takes the feature vector of a state as input and\\n\\noutputs an optimal action to execute in that state. The action is optimal if it maximizes the\\n\\nexpected average reward.\\n\\nReinforcement learning solves a particular kind of problems where\\n\\ndecision making is sequential, and the goal is long-term, such as game\\n\\nplaying, robotics, resource management, or logistics. In this book, I\\n\\nput emphasis on one-shot decision making where input examples are\\n\\nindependent of one another and the predictions made in the past. I\\n\\nleave reinforcement learning out of the scope of this book.\\n\\n2It could look counter-intuitive that learning could beneÔ¨Åt from adding more unlabeled examples. It seems\\n\\nlike we add more uncertainty to the problem. However, when you add unlabeled examples, you add more\\n\\ninformation about your problem: a larger sample reÔ¨Çects better the probability distribution the data we\\n\\nlabeled came from. Theoretically, a learning algorithm should be able to leverage this additional information.\\n\\nAndriy Burkov\\n\\nThe Hundred-Page Machine Learning Book - Draft\\n\\n4\\n\\n\\n\\n\\n\\n\\nPage 9:\\n\\n1.3\\n\\nHow Supervised Learning Works\\n\\nIn this section, I brieÔ¨Çy explain how supervised learning works so that you have the picture\\n\\nof the whole process before we go into detail. I decided to use supervised learning as an\\n\\nexample because it‚Äôs the type of machine learning most frequently used in practice.\\n\\nThe supervised learning process starts with gathering the data. The data for supervised\\n\\nlearning is a collection of pairs (input, output). Input could be anything, for example, email\\n\\nmessages, pictures, or sensor measurements. Outputs are usually real numbers, or labels (e.g.\\n\\n‚Äúspam‚Äù, ‚Äúnot_spam‚Äù, ‚Äúcat‚Äù, ‚Äúdog‚Äù, ‚Äúmouse‚Äù, etc). In some cases, outputs are vectors (e.g.,\\n\\nfour coordinates of the rectangle around a person on the picture), sequences (e.g. [‚Äúadjective‚Äù,\\n\\n‚Äúadjective‚Äù, ‚Äúnoun‚Äù] for the input ‚Äúbig beautiful car‚Äù), or have some other structure.\\n\\nLet‚Äôs say the problem that you want to solve using supervised learning is spam detection.\\n\\nYou gather the data, for example, 10,000 email messages, each with a label either ‚Äúspam‚Äù or\\n\\n‚Äúnot_spam‚Äù (you could add those labels manually or pay someone to do that for us). Now,\\n\\nyou have to convert each email message into a feature vector.\\n\\nThe data analyst decides, based on their experience, how to convert a real-world entity, such\\n\\nas an email message, into a feature vector. One common way to convert a text into a feature\\n\\nvector, called bag of words, is to take a dictionary of English words (let‚Äôs say it contains'}, {'role': 'assistant', 'content': 'Thought: I now know the final answer\\nFinal Answer: \\n\\nPage 8:\\n\\n1.2.3\\n\\nSemi-Supervised Learning\\n\\nIn semi-supervised learning, the dataset contains both labeled and unlabeled examples.\\n\\nUsually, the quantity of unlabeled examples is much higher than the number of labeled\\n\\nexamples. The goal of a semi-supervised learning algorithm is the same as the goal of\\n\\nthe supervised learning algorithm. The hope here is that using many unlabeled examples can\\n\\nhelp the learning algorithm to Ô¨Ånd (we might say ‚Äúproduce‚Äù or ‚Äúcompute‚Äù) a better model2.'}])], token_usage=UsageMetrics(total_tokens=51518, prompt_tokens=50253, cached_prompt_tokens=0, completion_tokens=1265, successful_requests=9))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw='To answer the question: \"What\\'s an AI Agent?\"\\n\\n**Direct Answer:** \\nAn intelligent agent is a program that can perform tasks that would typically require human intelligence.', pydantic=None, json_dict=None, tasks_output=[TaskOutput(description='Answer: Whats AI Agent?', name='Answer: Whats AI Agent?', expected_output='Short and clear answer from the PDF.', summary='Answer: Whats AI Agent?...', raw='To answer the question: \"What\\'s an AI Agent?\"\\n\\n**Direct Answer:** \\nAn intelligent agent is a program that can perform tasks that would typically require human intelligence.', pydantic=None, json_dict=None, agent='PDF Knowledge Expert', output_format=<OutputFormat.RAW: 'raw'>, messages=[{'role': 'user', 'content': 'You are PDF Knowledge Expert. Prioritize PDF content, use Wikipedia strictly as fallback.\\n\\nYour goal is: Answer questions accurately using PDF content first, Wikipedia only as fallback\\n\\nSTRICT RULES:\\n1. FIRST search the PDF for relevant content using the PDF tool\\n2. ONLY if PDF search returns NO results, then use Wikipedia\\n3. NEVER invent or add external knowledge\\n4. Always cite your source: (PDF) or (Wikipedia)\\n5. If no information found in either source, say: \"I couldn\\'t find this information in the PDF or Wikipedia.\"\\n\\nQUESTION: Answer: Semi-Supervised Learning?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nSEARCH INSTRUCTIONS:\\n1. Search PDF for relevant content\\n2. If PDF has content, use it\\n3. If PDF has NO content, search Wikipedia\\n4. If neither has content, state clearly\\n\\nANSWER FORMAT:\\n- Start with direct answer\\n- Include key points\\n- End with source: (PDF) or (Wikipedia)'}, {'role': 'assistant', 'content': 'To answer the question: \"Semi-Supervised Learning?\"\\n\\n**Direct Answer:**\\nSemi-supervised learning is the field of study that focuses on the development of algorithms that learn from both labeled and unlabeled data.\\n\\n**Key Points:**\\n\\n- Semi-supervised learning combines supervised and unsupervised learning techniques.\\n- It is used in scenarios where large amounts of labeled data are not available but unlabeled data is abundant.\\n- The goal of semi-supervised learning is to reduce the need for labeled data and improve the overall performance of machine learning models.\\n- Semi-supervised learning algorithms can be divided into two main categories: graph-based and manifold-based methods.\\n\\n**Source:** (Wikipedia)'}, {'role': 'user', 'content': 'You are PDF Knowledge Expert. Prioritize PDF content, use Wikipedia strictly as fallback.\\n\\nYour goal is: Answer questions accurately using PDF content first, Wikipedia only as fallback\\n\\nSTRICT RULES:\\n1. FIRST search the PDF for relevant content using the PDF tool\\n2. ONLY if PDF search returns NO results, then use Wikipedia\\n3. NEVER invent or add external knowledge\\n4. Always cite your source: (PDF) or (Wikipedia)\\n5. If no information found in either source, say: \"I couldn\\'t find this information in the PDF or Wikipedia.\"\\n\\nQUESTION: Answer: Whats AI Agent?\\n\\nThis is the expected criteria for your final answer: Short and clear answer from the PDF.\\nyou MUST return the actual complete content as the final answer, not a summary.\\n\\nSEARCH INSTRUCTIONS:\\n1. Search PDF for relevant content\\n2. If PDF has content, use it\\n3. If PDF has NO content, search Wikipedia\\n4. If neither has content, state clearly\\n\\nANSWER FORMAT:\\n- Start with direct answer\\n- Include key points\\n- End with source: (PDF) or (Wikipedia)'}, {'role': 'assistant', 'content': 'To answer the question: \"What\\'s an AI Agent?\"\\n\\n**Direct Answer:** \\nAn intelligent agent is a program that can perform tasks that would typically require human intelligence.'}])], token_usage=UsageMetrics(total_tokens=55145, prompt_tokens=52839, cached_prompt_tokens=0, completion_tokens=2306, successful_requests=16))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"input\": \"Whats AI Agent?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffc4ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
